{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a439ee9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from Dataloader import *\n",
    "from utils import download, overhaul_segments, plot_trajectory_on_map\n",
    "\n",
    "import folium\n",
    "import zipfile\n",
    "import requests\n",
    "\n",
    "import pandas as pd\n",
    "import pyarrow\n",
    "import pyarrow.parquet\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd300124",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_links = {\"Jan\": \"http://aisdata.ais.dk/2023/aisdk-2023-01.zip\",\n",
    "              \"Feb\": \"http://aisdata.ais.dk/2023/aisdk-2023-02.zip\",\n",
    "              \"Mar\": \"http://aisdata.ais.dk/2023/aisdk-2023-03.zip\",\n",
    "              \"Apr\": \"http://aisdata.ais.dk/2023/aisdk-2023-04.zip\",\n",
    "              \"May\": \"http://aisdata.ais.dk/2023/aisdk-2023-05.zip\",\n",
    "              \"Jun\": \"http://aisdata.ais.dk/2023/aisdk-2023-06.zip\",\n",
    "              \"Jul\": \"http://aisdata.ais.dk/2023/aisdk-2023-07.zip\",\n",
    "              \"Aug\": \"http://aisdata.ais.dk/2023/aisdk-2023-08.zip\",\n",
    "              \"Sep\": \"http://aisdata.ais.dk/2023/aisdk-2023-09.zip\",\n",
    "              \"Oct\": \"http://aisdata.ais.dk/2023/aisdk-2023-10.zip\",\n",
    "              \"Nov\": \"http://aisdata.ais.dk/2023/aisdk-2023-11.zip\",\n",
    "              \"Dec\": \"http://aisdata.ais.dk/2023/aisdk-2023-12.zip\"}\n",
    "\n",
    "data_dir = \"../data/unprocessed_data\"\n",
    "end_dir = \"../data/processed_data\"\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "os.makedirs(end_dir, exist_ok=True)\n",
    "\n",
    "for month, link in data_links.items():\n",
    "    filename = link.split(\"/\")[-1]\n",
    "    filepath = os.path.join(data_dir, filename)\n",
    "\n",
    "    # Extract month number from filename\n",
    "    month_num = filename.split(\"-\")[2].replace(\".zip\", \"\")\n",
    "\n",
    "    # Check if all parquet files for this month already exist\n",
    "    # Quick check: if folder has files matching this month pattern\n",
    "    existing_parquets = [f for f in os.listdir(end_dir) if f.startswith(f\"aisdk-2023-{month_num}-\") and f.endswith('.parquet')]\n",
    "    \n",
    "    # A month should have 28-31 parquet files\n",
    "    if len(existing_parquets) >= 28:\n",
    "        print(f\"‚è≠Ô∏è  Skipping month {month}: {len(existing_parquets)} parquet files already exist\")\n",
    "        continue\n",
    "\n",
    "    # Download if needed\n",
    "    if os.path.exists(filepath):\n",
    "        print(f\"‚è≠Ô∏è  Skipping download for month {month}: {filepath} (already exists)\")\n",
    "    else:\n",
    "        print(f\"Downloading data for {month}...\")\n",
    "        download(link, filepath)\n",
    "        print(f\"Downloaded data for {month}\")\n",
    "\n",
    "    # Open ZIP once and process all CSV files\n",
    "    with zipfile.ZipFile(filepath, 'r') as zip_ref:\n",
    "        csv_files = [f for f in zip_ref.namelist() if f.endswith('.csv')]\n",
    "        print(f\"Found {len(csv_files)} CSV files in {filename}\")\n",
    "        \n",
    "        for csv_filename in csv_files:\n",
    "            output_filename = csv_filename.replace('.csv', '.parquet')\n",
    "            output_path = os.path.join(end_dir, output_filename)\n",
    "            \n",
    "            if os.path.exists(output_path):\n",
    "                print(f\"‚è≠Ô∏è  Skipping {output_filename} (already exists)\")\n",
    "                continue\n",
    "            \n",
    "            print(f\"üìù Processing: {csv_filename}\")\n",
    "            \n",
    "            data = Dataloader(\n",
    "                file_path=\"\",\n",
    "                out_path=output_path,\n",
    "                zip_path=filepath,\n",
    "                csv_internal_path=csv_filename\n",
    "            )\n",
    "            data.clean_data()\n",
    "\n",
    "    print(f\"‚úÖ Processed {month}\")\n",
    "\n",
    "    # Remove ZIP after processing \n",
    "    os.remove(filepath)\n",
    "    print(f\"üóëÔ∏è  Removed {filename}\")\n",
    "\n",
    "print(\"üéâ All data processed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb9ec0b",
   "metadata": {},
   "source": [
    "# Plotting the clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8a0300",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data/processed_data\"\n",
    "dataloader = Dataloader(out_path=path)\n",
    "# df = dataloader.load_data(date_folders = [\"aisdk-2023-01-01.parquet\",\"aisdk-2023-01-02.parquet\",\"aisdk-2023-01-03.parquet\",\n",
    "#                                           \"aisdk-2023-01-04.parquet\",\"aisdk-2023-01-05.parquet\",\"aisdk-2023-01-06.parquet\",\n",
    "#                                           \"aisdk-2023-01-07.parquet\",\"aisdk-2023-01-08.parquet\",\"aisdk-2023-01-09.parquet\",\n",
    "#                                           \"aisdk-2023-01-10.parquet\"]) # for specific files\n",
    "df = dataloader.load_data()  # load all files in the processed_data folder\n",
    "# Ensure ship and segment can be told apart by adding column for date\n",
    "df['Date'] = df['Timestamp'].dt.date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e808759d",
   "metadata": {},
   "source": [
    "Overhauling the segment method from the data cleaning function to ensure overnight segments are not split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f68eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = overhaul_segments(df)\n",
    "df.drop(columns=['Segment'], inplace=True)\n",
    "df.rename(columns={\"Segment_ID\": \"Segment\"}, inplace=True)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f4ef3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_trajectory_on_map(df, percentage_of_vessels=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a772811",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "marinetime-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
